DP和DDP是pytorch中常用的两种并行化策略。

- DP适合与单机多卡；DDP适合于多机多卡。
- DP是基于parameter server并行策略的，而DDP基于allreduce并行。
- DP相对于DDP效率更低（GIL锁，由于单进程多线程）
- DP是多线程，DDP多进程。因此DDP需要用pytorch的launch来运行DDP程序。
- 



#### pytorch中的DP（data parallel）机制

数据并行的思路就是讲一个batch拆分成多个等大小的batch，分配给不同的GPU进行运算，最后将结果进行整合，得到最终的输出。

DataParallel适用于单机多卡的场景。

pytorch对应的api：

> https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel

~~~python
torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)
参数
module: 网络模型
device_ids: 需要并行的gpu编号，list形式，如[0,1,2]
output_device: 输出结果存放的位置，一般是cuda:0，第一张卡
~~~

实现方式简单，只需要用DataParallel将原model进行wrap即可。其余代码无需改动。

~~~python
model = nn.DataParallel(model)
~~~

DP的基本原理是：以一张卡作为reducer，首先将模型分发给各个GPU，将一个batch的数据进行拆分，分给各个GPU各自运算，然后再reducer上进行融合处理。这个操作会导致负载不均衡，reducer卡开销比其他卡要更大。

需要注意：被wrap的model在每次forward操作时，都要重新将cuda0（reducer卡）上的module参数copy到各个GPU，因此，各个GPU上运行的实际上是model的副本，并且这些副本在一次传播结束之后就被销毁。所以，在forward中更新全局变量在DP模式下是不可取的。

forward之后，得到各个参数的梯度，然后将这些梯度传到cuda0进行汇总，更新参数。准备下次再次分发模型到各个GPU。

DP不支持apex半精度训练。



#### DDP（distributed data parallel）并行化

DDP本意是针对多机多卡的情况，即多个node组成的GPU计算集群，进行分布式训练的。但是DDP也可以用于单机多卡，并且比DP效率更高。因为DDP是基于多进程（MultiProcessing），一般是一个进程控制一个GPU进行计算。





























