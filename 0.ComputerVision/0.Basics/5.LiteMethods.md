CNN模型轻量化、模型压缩



主要思路：

- 剪枝

- 蒸馏

- 轻量化模型

- 量化、二值化



#### 剪枝（pruning）

剪枝的两种不同类别：

**结构化剪枝**：剪通道或者层，便于实现，prun之后和正常的convnet一样。通常采用的是结构化剪枝。

**非结构化剪枝**：剪每个kernel权重，因此会得到稀疏的权重矩阵。需要配合处理稀疏加速的库才能真正实现加速。

剪枝策略的通用的基本思路：先训练大网络，并且在训练过程中对feature map施加稀疏化约束，使得各个feature map重要性有所区别，然后利用规则将不重要的feature map舍弃，从而降低模型计算量和参数。

剪枝的通用pipeline：带稀疏约束的预训练 —— 剪枝 —— finetune —— 剪枝 —— fiinetune （迭代循环）

通常称为**3-stage prun，即【train--prun--finetune】**



#### 蒸馏（distillation）





#### 轻量化（efficient model）





#### 量化（quantization）

