CNN模型轻量化、模型压缩



主要思路：

- 剪枝

- 蒸馏

- 轻量化模型

- 量化、二值化



#### 剪枝（pruning）

剪枝的两种不同类别：

**结构化剪枝**：剪通道或者层，便于实现，prun之后和正常的convnet一样。通常采用的是结构化剪枝。

**非结构化剪枝**：剪每个kernel权重，因此会得到稀疏的权重矩阵。需要配合处理稀疏加速的库才能真正实现加速。

剪枝策略的通用的基本思路：先训练大网络，并且在训练过程中对feature map施加稀疏化约束，使得各个feature map重要性有所区别，然后利用规则将不重要的feature map舍弃，从而降低模型计算量和参数。

剪枝的通用pipeline：带稀疏约束的预训练 —— 剪枝 —— finetune —— 剪枝 —— fiinetune （迭代循环）

通常称为**3-stage prun，即【train--prun--finetune】**



#### 蒸馏（distillation）

知识蒸馏也是一种构建小规模模型的方式，蒸馏的基本思路是：先用大数据集训练一个大网络，然后保留下大网络的预测结果，即输出去的logits，用来代替真实的label，然后用一个小网络去拟合大网络的输出结果，这个过程也就是在学习大网络预测的分布，从而模仿大网络的判别结果。

这个过程中，大网络称为teacher network，小网络称为student network。蒸馏法还有后续的一些发展，如不仅学教师的logits，也学习教师网络的中间层信息。等等。



#### 轻量化模型（efficient model）

这个方案的基本思路是，通过对于模型结构的优化，比如改进卷积方式等，获得参数量和计算量更小的模型。代表模型有mobilenet系列和shufflenet系列。



#### 量化（quantization）

模型量化的思路是，用较低bit数的数据类型代替常用的float32和double64，从而降低计算量和模型规模。比较常见的如8bit量化。另外，1-bit量化方法也有相关研究。









