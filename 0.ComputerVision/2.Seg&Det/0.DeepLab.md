#### DeepLab系列语义分割模型进化过程梳理



#### DeepLab系列各个模型的关键点：

- deeplab v1，使用**空洞卷积（Atrous conv）** 、使用**CRF**
- deeplab v2，提出**ASPP** ，通过改变dilation rate实现金字塔
- deeplab v3，改进ASPP，增加**1x1 conv与全局GAP**
- deeplab v3p，模型整体改成**encoder-decoder结构** ，Xception，利用**DWConv**



参考论文：

**DeepLabv1**： SEMANTICIMAGESEGMENTATION WITHDEEPCON-VOLUTIONALNETS ANDFULLYCONNECTEDCRFS

**DeepLabv2**： DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution,   and Fully Connected CRFs

**DeepLabv3**：Rethinking Atrous Convolution for Semantic Image Segmentation

**DeepLabv3+**：Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation



#### DeepLab V1

Refer 0.0.1 SegBasics

DeepLab-LargeFOV是deeplab v1的一个variant。



#### DeepLab V2

deeplab v1和v2都是基于atrous conv以及CRF的，不同的在于：v2用了resnet的backbone，v1只用了vgg。另外，v2首次提出了**ASPP模块**。

对于32x的resnet，将最后两层的下采样改成r=2的dilated conv，从而使得最小的尺寸为8x，上采样只需要upsample 8倍，从而降低定位损失。

**ASPP（Atrous Spatial Pyramid Pooling）** 的结构如下：

![img](assets/1*_8p_KTPr5N0HSeIKV35G_g.png)



ASPP本质上还是一个SPP，即空间金字塔池化。在SPPnet中，SPP被用来将不同尺寸的ROI pool到同一个尺寸，用于后袖的训练；而在PSPNet中，也用到SPP的方法，但是是针对同样大小的feature map来获得不同尺寸（代表不同范围）的pooling结果，然后resize后拼接。ASPP用dilated conv的方式代替了常规的池化稠密的取average或max 的过程。

ASPP module的代码示例：

~~~python
import torch
import torch.nn as nn

class ASPP(nn.Module):
    def __init__(self, out_channels=256, dropout=0.1):
        super(ASPP, self).__init__()
        drop_rate = dropout
        dilation_rates = [6, 12, 18, 24]
        features = []
        for idx, dr in enumerate(dilation_rates):
            features.append(
                nn.Sequential(
                    nn.Conv2d(out_channels,
                            out_channels,
                            kernel_size=3,
                            stride=1,
                            padding=dr,
                            dilation=dr,
                            bias=True),
                    nn.ReLU(inplace=True),
                    nn.Dropout2d(p=drop_rate),
                )
            )
        self.features = nn.ModuleList(features)

    def forward(self, x):
        outs = []
        for f in self.features:
            outs.append(f(x))
        out = torch.cat(outs, dim=1)
        return out
~~~



deeplabv2和它之前的版本largeFOV的对比：

![image-20210617141922131](assets/image-20210617141922131.png)

#### DeepLab V3

![image-20210617190857066](assets/image-20210617190857066.png)

Deeplab v3的改进点：

1. 用了**更多的、rate不同的atrous conv** ，避免下采样导致的分辨率损失。

2. ASPP也进行了改进，在并行的各个rate的atrous conv之外，又增加了**1x1的conv**和**全局的pooling**，和空洞卷积的结果一起concat。这个改动的原因是，大rate的atrous conv在feature map尺寸很小的时候，真实有效的（非padding位置的）计算实际上很有限（因为atrous的空间范围大，且只在边界有值），因此加入1x1 conv进行补偿，并用image pool整合全局信息。

   

   ![image-20210617191300704](assets/image-20210617191300704.png)

   

#### DeepLab V3+

Deeplab v3p 的主要改动的点在于将以往的优化backbone的策略修改为优化encoder+decoder。顺序还是通过backbone + ASPP提特征，然后将结果输入decoder进行解码恢复。

![image-20210617193309053](assets/image-20210617193309053.png)



其他的几个优化的点主要有：

1. 可以通过空洞卷积控制分辨率，从而在runtime和precision之间进行折中。
2. 采用Xception，将conv换成depthwise separable conv，从而提高效率。

![image-20210617193707999](assets/image-20210617193707999.png)



